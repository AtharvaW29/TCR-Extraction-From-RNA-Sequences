{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqfrVRbWpLXm"
      },
      "source": [
        "### **TASK 2**\n",
        "##**Create a simple tool that will be able to extract TCR sequences from bulk-RNAseq**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKsdYr2vr4JH"
      },
      "source": [
        "###We shall be using MiXCR owing to its superior features over TRUST4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlnjPjPHpgmm"
      },
      "source": [
        "# Let's start by connecting our drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NsGm_HVpXnG",
        "outputId": "9fc309d5-7e00-449c-88db-1027ef99da04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "#Mounting Google Drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNGojhc4pn0u"
      },
      "source": [
        "#Installing essential pacakges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvGX-rPfpnHQ",
        "outputId": "e3cee4cc-b448-4bc7-b615-8a3acc627b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.12/dist-packages (1.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from matplotlib-venn) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from matplotlib-venn) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from matplotlib-venn) (1.16.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "!pip install matplotlib-venn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UV5m9B4qGNm"
      },
      "source": [
        "#Importing all necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "clbV8ntQqKxu"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from sklearn.pipeline import Pipeline\n",
        "from collections import Counter\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from matplotlib_venn import venn3\n",
        "from functools import reduce\n",
        "import shutil\n",
        "import sys\n",
        "import os\n",
        "# Parallel Processing with Multiprocessing\n",
        "import gzip\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
        "import shutil\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import multiprocessing as mp\n",
        "import glob, math\n",
        "import condacolab\n",
        "import shlex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuIRDevwqjOu"
      },
      "source": [
        "#Please refer condacolab's documentation for installtion\n",
        "#[Here...](https://pypi.org/project/condacolab/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUs8flgiqa_W",
        "outputId": "2b057ded-187a-4968-99c0-a9f1c37b1939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:17\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odg_CJoPqxpW",
        "outputId": "0abc5a9a-dc84-4189-ebf4-07cc6594c991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "condacolab.check()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UElptbgRq3K-"
      },
      "source": [
        "#Add conda to the path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rg00Soipq51G"
      },
      "outputs": [],
      "source": [
        "conda_path = '/usr/local/bin'\n",
        "os.environ['CONDA_EXE'] = os.path.join(conda_path, 'conda')\n",
        "os.environ['PATH'] = f\"{conda_path}:{os.environ['PATH']}\"\n",
        "sys.path.insert(0, os.path.join(conda_path, '..', 'lib', 'python3.10', 'site-packages'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkX68v6CrKxm"
      },
      "source": [
        "#Steps to install MiXCR\n",
        "#**You will need to get a free locense to run this package**\n",
        "#Please follow the link here\n",
        "[License Link](https://mixcr.com/mixcr/getting-started/milm/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rNMxbxd6rQKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee17ed01-ac78-48ea-eea6-e66523e260fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "/usr/local/bin\n",
            "--2025-09-02 18:41:57--  https://github.com/milaboratory/mixcr/releases/download/v4.6.0/mixcr-4.6.0.zip\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/33134597/6bdd7a80-9aea-4572-b796-6065ef5d1f8b?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-02T19%3A31%3A33Z&rscd=attachment%3B+filename%3Dmixcr-4.6.0.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-02T18%3A31%3A03Z&ske=2025-09-02T19%3A31%3A33Z&sks=b&skv=2018-11-09&sig=7e3QhLnl%2Fzp6NwNx4qmp%2BIrtR11HkFQ1J2ZO5M48cJ4%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1NjgzODcwOCwibmJmIjoxNzU2ODM4NDA4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.SyzR_Igr8uDfGB-LVvgavxZhKmkgW2dB7IRFRZ404xM&response-content-disposition=attachment%3B%20filename%3Dmixcr-4.6.0.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-09-02 18:41:57--  https://release-assets.githubusercontent.com/github-production-release-asset/33134597/6bdd7a80-9aea-4572-b796-6065ef5d1f8b?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-02T19%3A31%3A33Z&rscd=attachment%3B+filename%3Dmixcr-4.6.0.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-02T18%3A31%3A03Z&ske=2025-09-02T19%3A31%3A33Z&sks=b&skv=2018-11-09&sig=7e3QhLnl%2Fzp6NwNx4qmp%2BIrtR11HkFQ1J2ZO5M48cJ4%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1NjgzODcwOCwibmJmIjoxNzU2ODM4NDA4LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.SyzR_Igr8uDfGB-LVvgavxZhKmkgW2dB7IRFRZ404xM&response-content-disposition=attachment%3B%20filename%3Dmixcr-4.6.0.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 104617347 (100M) [application/octet-stream]\n",
            "Saving to: ‚Äòmixcr-4.6.0.zip‚Äô\n",
            "\n",
            "mixcr-4.6.0.zip     100%[===================>]  99.77M  14.5MB/s    in 6.8s    \n",
            "\n",
            "2025-09-02 18:42:04 (14.7 MB/s) - ‚Äòmixcr-4.6.0.zip‚Äô saved [104617347/104617347]\n",
            "\n",
            "Archive:  mixcr-4.6.0.zip\n",
            "  inflating: mixcr                   \n",
            "  inflating: LICENSE                 \n",
            "  inflating: mixcr.jar               \n"
          ]
        }
      ],
      "source": [
        "# Installation Steps for MiXCR\n",
        "%cd /\n",
        "%cd /usr/local/bin\n",
        "!wget https://github.com/milaboratory/mixcr/releases/download/v4.6.0/mixcr-4.6.0.zip\n",
        "!unzip mixcr-4.6.0.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6H0OkRK3rwl-"
      },
      "outputs": [],
      "source": [
        "# Setting up license key for MiXCR [Add this in our OS environment]\n",
        "os.environ['MI_LICENSE'] = 'E-UZCNDGRBYRVXJUSGMPFWBGRMAGYVBGJHUSXMTPRSHWVCSOGL'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NT70QXwrrdu",
        "outputId": "2ccf0bf1-957b-411e-f388-4809fc2c53d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: \u001b[1mmixcr\u001b[21m\u001b[0m [\u001b[33m-h\u001b[39m\u001b[0m] [\u001b[33m-v\u001b[39m\u001b[0m] [COMMAND]\n",
            "  \u001b[33m-h\u001b[39m\u001b[0m, \u001b[33m--help\u001b[39m\u001b[0m      Show this help message and exit.\n",
            "  \u001b[33m-v\u001b[39m\u001b[0m, \u001b[33m--version\u001b[39m\u001b[0m   Print version information and exit\n",
            "Base commands:\n",
            "  \u001b[1manalyze\u001b[21m\u001b[0m            Run full MiXCR pipeline for specific input.\n",
            "  \u001b[1malign\u001b[21m\u001b[0m              Builds alignments with V,D,J and C genes for input sequencing reads.\n",
            "  \u001b[1mrefineTagsAndSort\u001b[21m\u001b[0m  Applies error correction algorithm for tag sequences and sorts resulting file\n",
            "                       by tags.\n",
            "  \u001b[1massemblePartial\u001b[21m\u001b[0m    Assembles partially aligned reads into longer sequences.\n",
            "  \u001b[1mextend\u001b[21m\u001b[0m             Impute alignments or clones with germline sequences.\n",
            "  \u001b[1massemble\u001b[21m\u001b[0m           Assemble clones.\n",
            "  \u001b[1massembleContigs\u001b[21m\u001b[0m    Assemble full sequences.\n",
            "  \u001b[1mgroupClones\u001b[21m\u001b[0m        Group clones by cells. Required data with cell tags.\n",
            "  \u001b[1mfindAlleles\u001b[21m\u001b[0m        Find allele variants in clnx.\n",
            "  \u001b[1mfindShmTrees\u001b[21m\u001b[0m       Builds SHM trees.\n",
            "  \u001b[1mdownsample\u001b[21m\u001b[0m         Downsample clonesets.\n",
            "  \u001b[1mqc\u001b[21m\u001b[0m                 Perform quality control checks on results.\n",
            "Postanalysis commands:\n",
            "  \u001b[1mpostanalysis\u001b[21m\u001b[0m  Run postanalysis routines. This command has subcommands, use -h to see more\n",
            "Export commands:\n",
            "  \u001b[1mexportTables\u001b[21m\u001b[0m              CDR3 metrics, Diversity, V/J/VJ-Usage, CDR3/V-Spectratype, Overlap\n",
            "  \u001b[1mexportPreprocTables\u001b[21m\u001b[0m       Export preprocessing summary tables.\n",
            "  \u001b[1mexportPlots\u001b[21m\u001b[0m               Export postanalysis plots. This command has subcommands, use -h to see\n",
            "                              more\n",
            "  \u001b[1moverlapScatterPlot\u001b[21m\u001b[0m        Plot overlap scatter-plot.\n",
            "  \u001b[1mexportAlignments\u001b[21m\u001b[0m          Export V/D/J/C alignments into tab delimited file.\n",
            "  \u001b[1mexportAlignmentsPretty\u001b[21m\u001b[0m    Export verbose information about alignments.\n",
            "  \u001b[1mexportClones\u001b[21m\u001b[0m              Export assembled clones into tab delimited file.\n",
            "  \u001b[1mexportCloneGroups\u001b[21m\u001b[0m         Export clone groups into tab delimited file. Data should be processed\n",
            "                              by `groupClones`\n",
            "  \u001b[1mexportClonesPretty\u001b[21m\u001b[0m        Export verbose information about clones.\n",
            "  \u001b[1mexportShmTreesWithNodes\u001b[21m\u001b[0m   Export SHMTree as a table with a row for every clone or reconstructed\n",
            "                              node for each root (only one root if no single cell data)\n",
            "  \u001b[1mexportShmTrees\u001b[21m\u001b[0m            Export SHMTree as a table with a row for every SHM root in a table\n",
            "                              (single row if no single cell data)\n",
            "  \u001b[1mexportShmSingleCellTrees\u001b[21m\u001b[0m  Export SHM trees with one row per node. Tree may contain several roots,\n",
            "                              that will be exported in separate columns. Initial data for building\n",
            "                              tree should contain cell data.\n",
            "  \u001b[1mexportShmTreesNewick\u001b[21m\u001b[0m      Export SHMTree as newick\n",
            "  \u001b[1mexportReports\u001b[21m\u001b[0m             Export MiXCR reports.\n",
            "  \u001b[1mexportReportsTable\u001b[21m\u001b[0m        Export reports from files in tabular format.\n",
            "  \u001b[1mexportQc\u001b[21m\u001b[0m                  Export QC plots. This command has subcommands, use -h to see more\n",
            "  \u001b[1mexportClonesOverlap\u001b[21m\u001b[0m       Build cloneset overlap and export into tab delimited file.\n",
            "  \u001b[1mexportAirr\u001b[21m\u001b[0m                Exports a clns, clna or vdjca file to Airr formatted tsv file.\n",
            "Util commands:\n",
            "  \u001b[1mexportReadsForClones\u001b[21m\u001b[0m       Export reads for particular clones from \"clones & alignments\" (*.clna)\n",
            "                               file.\n",
            "  \u001b[1mexportAlignmentsForClones\u001b[21m\u001b[0m  Export alignments for particular clones from \"clones & alignments\" (*.\n",
            "                               clna) file.\n",
            "  \u001b[1mexportReads\u001b[21m\u001b[0m                Export original reads from vdjca file.\n",
            "  \u001b[1mmergeAlignments\u001b[21m\u001b[0m            Merge several *.vdjca files with alignments into a single alignments\n",
            "                               file.\n",
            "  \u001b[1mfilterAlignments\u001b[21m\u001b[0m           Filter alignments.\n",
            "  \u001b[1msortAlignments\u001b[21m\u001b[0m             Sort alignments in vdjca file by read id.\n",
            "  \u001b[1msortClones\u001b[21m\u001b[0m                 Sort clones by sequence. Clones in the output file will be sorted by\n",
            "                               clonal sequence, which allows to build overlaps between clonesets.\n",
            "  \u001b[1malignmentsDiff\u001b[21m\u001b[0m             Calculates the difference between two .vdjca files.\n",
            "  \u001b[1mclonesDiff\u001b[21m\u001b[0m                 Calculates the difference between two .clns files.\n",
            "  \u001b[1mversionInfo\u001b[21m\u001b[0m                Output information about MiXCR version which generated the file.\n",
            "  \u001b[1mslice\u001b[21m\u001b[0m                      Slice vdjca|clns|clna|shmt file.\n",
            "  \u001b[1mexportPreset\u001b[21m\u001b[0m               Export a preset file given the preset name or source file and a set of\n",
            "                               mix-ins\n",
            "  \u001b[1mbuildLibrary\u001b[21m\u001b[0m               Build custom reference library\n",
            "  \u001b[1mmergeLibrary\u001b[21m\u001b[0m               Merge multiple reference libraries in one file\n",
            "  \u001b[1mdebugLibrary\u001b[21m\u001b[0m               Debug reference library file\n",
            "  \u001b[1mlistPresets\u001b[21m\u001b[0m                Show all available presets\n"
          ]
        }
      ],
      "source": [
        "# verify if it was installed correclty\n",
        "!mixcr -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Zj97NoRizgQ2"
      },
      "outputs": [],
      "source": [
        "# Step 1 Pulling the data systematically from the mounted drive\n",
        "base_dir = \"/content/drive/MyDrive/Bio_Informatics_RA_Assignment\"\n",
        "\n",
        "patients = [\"Patient1\"]\n",
        "\n",
        "patient_files = [\"Patient1_merged_1.fastq.gz\", \"Patient1_merged_2.fastq.gz\"]\n",
        "\n",
        "# Output dir for results\n",
        "results_dir = os.path.join(base_dir, \"results\")\n",
        "os.makedirs(results_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X5jycVfSzv9P"
      },
      "outputs": [],
      "source": [
        "# Optimizing IO\n",
        "def stage_data_locally(patients, patient_files, base_dir):\n",
        "    \"\"\"\n",
        "    Copies necessary FASTQ and reference files from Drive to the local Colab disk.\n",
        "    Returns a dictionary of local FASTQ paths for each patient.\n",
        "    \"\"\"\n",
        "    local_data_dir = \"/content/local_data\"\n",
        "    os.makedirs(local_data_dir, exist_ok=True)\n",
        "\n",
        "    local_paths = {}\n",
        "    for patient in patients:\n",
        "        fastq_dir = os.path.join(base_dir, patient)\n",
        "\n",
        "        # Copy FASTQ files\n",
        "        r1_name, r2_name = patient_files[patient]\n",
        "        local_r1_path = os.path.join(local_data_dir, r1_name)\n",
        "        local_r2_path = os.path.join(local_data_dir, r2_name)\n",
        "\n",
        "        print(f\"Copying {os.path.join(fastq_dir, r1_name)} to {local_r1_path}\")\n",
        "        shutil.copy(os.path.join(fastq_dir, r1_name), local_r1_path)\n",
        "        shutil.copy(os.path.join(fastq_dir, r2_name), local_r2_path)\n",
        "\n",
        "        local_paths[patient] = (local_r1_path, local_r2_path)\n",
        "\n",
        "    print(\"All FASTQ files copied to local disk.\")\n",
        "    return local_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4JoFm3AUzz2u"
      },
      "outputs": [],
      "source": [
        "# Create a local directory to store results for efficiency\n",
        "local_results_dir = \"/content/local_results\"\n",
        "os.makedirs(local_results_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWMaUkjBzVfO"
      },
      "source": [
        "\n",
        "# üîß MiXCR ‚Äî Optimized Pipeline (Threading ¬∑ Chunking ¬∑ Caching)\n",
        "\n",
        "This section adds a robust, Colab-friendly workflow for **MiXCR**. Key features:\n",
        "\n",
        "- Uses **multi-threading** automatically (`-t` set to all available CPU cores).\n",
        "- **Streams** from `.fastq.gz` directly (no full decompression).\n",
        "- Optional **chunking** for very large FASTQs, with smart per-chunk threading.\n",
        "- **Caching**: skips steps if outputs are already up-to-date.\n",
        "- Clean **logging** + **reports** for reproducibility.\n",
        "\n",
        "> ‚úÖ Recommended free Colab runtime: **CPU** (High-RAM if available). MiXCR does **not** use GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aCE8vqnZzW9o"
      },
      "outputs": [],
      "source": [
        "# State the Path first\n",
        "mixcr_path = \"/usr/local/bin/mixcr\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4bSRNDP0DTu",
        "outputId": "1f953a35-3486-4d90-bd31-c22e45176439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$ wget -q https://github.com/shenwei356/seqkit/releases/download/v2.8.2/seqkit_linux_amd64.tar.gz -O /content/seqkit.tar.gz\n",
            "$ tar -xzf /content/seqkit.tar.gz -C /content/\n",
            "$ chmod +x /content/bin/seqkit\n",
            "PATH -> /content/bin:/usr/local/bin:/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
            "$ mixcr -v || true\n",
            "$ seqkit version || true\n",
            "\n",
            "‚úÖ Tooling ready.\n"
          ]
        }
      ],
      "source": [
        "MIXCR_VERSION = \"4.6.0\"  # change if needed\n",
        "BIN_DIR = \"/content/bin\"\n",
        "os.makedirs(BIN_DIR, exist_ok=True)\n",
        "\n",
        "def run(cmd, **kwargs):\n",
        "    print(\"$\", cmd)\n",
        "    return subprocess.run(cmd, shell=True, check=True, text=True, **kwargs)\n",
        "# SeqKit install (static Linux binary)\n",
        "seqkit_path = os.path.join(BIN_DIR, \"seqkit\")\n",
        "if not os.path.exists(seqkit_path):\n",
        "    run(\"wget -q https://github.com/shenwei356/seqkit/releases/download/v2.8.2/seqkit_linux_amd64.tar.gz -O /content/seqkit.tar.gz\")\n",
        "    run(\"tar -xzf /content/seqkit.tar.gz -C /content/\")\n",
        "    # The tar expands to a directory with the binary inside\n",
        "    found = False\n",
        "    for root, dirs, files in os.walk(\"/content\"):\n",
        "        if \"seqkit\" in files and \"linux_amd64\" in root:\n",
        "            shutil.copy(os.path.join(root, \"seqkit\"), seqkit_path)\n",
        "            found = True\n",
        "            break\n",
        "    if not found:\n",
        "        # fallback: sometimes the tar unpacks directly\n",
        "        if os.path.exists(\"/content/seqkit\"):\n",
        "            shutil.copy(\"/content/seqkit\", seqkit_path)\n",
        "    run(f\"chmod +x {seqkit_path}\")\n",
        "else:\n",
        "    print(\"SeqKit already installed:\", seqkit_path)\n",
        "\n",
        "# Put BIN_DIR on PATH for this session\n",
        "os.environ[\"PATH\"] = f\"{BIN_DIR}:\" + os.environ[\"PATH\"]\n",
        "print(\"PATH ->\", os.environ[\"PATH\"])\n",
        "run(\"mixcr -v || true\")\n",
        "run(\"seqkit version || true\")\n",
        "print(\"\\n‚úÖ Tooling ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxNCxQ8x0XoO"
      },
      "source": [
        "#Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "74HF8ffM0a_O"
      },
      "outputs": [],
      "source": [
        "def cpu_threads():\n",
        "  try:\n",
        "    n = mp.cpu_count() or 2\n",
        "  except Excetpion as e:\n",
        "    n = 2\n",
        "  return max(1, n)\n",
        "\n",
        "def newer_than(output, *inputs):\n",
        "    out = Path(output)\n",
        "    if not out.exists():\n",
        "        return False\n",
        "    out_mtime = out.stat().st_mtime\n",
        "    for i in inputs:\n",
        "        p = Path(i)\n",
        "        if not p.exists():\n",
        "            return False\n",
        "        if p.stat().st_mtime > out_mtime:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def sh(cmd):\n",
        "    print(f\"$ {cmd}\")\n",
        "    # stream output live\n",
        "    proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in proc.stdout:\n",
        "        print(line, end=\"\")\n",
        "    rc = proc.wait()\n",
        "    if rc != 0:\n",
        "        raise RuntimeError(f\"Command failed with exit code {rc}: {cmd}\")\n",
        "    return rc\n",
        "\n",
        "def _run(cmd, cwd=None):\n",
        "    \"\"\"Run a shell command with full error surfacing.\"\"\"\n",
        "    print(\"$\", \" \".join(shlex.quote(c) for c in cmd))\n",
        "    res = subprocess.run(cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if res.returncode != 0:\n",
        "        raise subprocess.CalledProcessError(res.returncode, cmd, output=res.stdout, stderr=res.stderr)\n",
        "    return res\n",
        "\n",
        "def _pair_chunk_files(r1_dir, r2_dir):\n",
        "    r1 = sorted(list(Path(r1_dir).glob(\"*.fastq.gz\")) + list(Path(r1_dir).glob(\"*.fq.gz\")))\n",
        "    r2 = sorted(list(Path(r2_dir).glob(\"*.fastq.gz\")) + list(Path(r2_dir).glob(\"*.fq.gz\")))\n",
        "    if len(r1) != len(r2):\n",
        "        raise ValueError(f\"R1/R2 chunk mismatch: {len(r1)} vs {len(r2)}\")\n",
        "    return list(zip(r1, r2))\n",
        "\n",
        "def _choose_parallelism(n_chunks, total_threads):\n",
        "    \"\"\"\n",
        "    Budget threads safely: threads_per_job * jobs <= total_threads.\n",
        "    Prefer ~2‚Äì4 threads per chunk if possible.\n",
        "    \"\"\"\n",
        "    total_threads = max(1, int(total_threads or (os.cpu_count() or 1)))\n",
        "    if n_chunks <= 1:\n",
        "        return 1, total_threads  # 1 job, all threads\n",
        "\n",
        "    # start with 4 threads per job if we can afford it\n",
        "    t_per = min(4, total_threads)\n",
        "    jobs = max(1, min(n_chunks, total_threads // t_per))\n",
        "    if jobs == 0:\n",
        "        jobs = 1\n",
        "        t_per = total_threads\n",
        "    # recompute t_per to fully use available threads\n",
        "    t_per = max(1, total_threads // jobs)\n",
        "    return jobs, t_per\n",
        "\n",
        "def _align_one_chunk(mixcr_path, preset, species, reads_layout, r1, r2, out_prefix, threads, report_path):\n",
        "    \"\"\"\n",
        "    Faithful to your working single-run flags.\n",
        "    mixcr align --preset rna-seq --species hsa -OreadsLayout=Collinear --threads N R1 R2 out.vdjca\n",
        "    \"\"\"\n",
        "    align_cmd = [\n",
        "        mixcr_path, \"align\",\n",
        "        \"--preset\", preset,\n",
        "        \"--species\", species,\n",
        "        \"-OreadsLayout=\" + reads_layout,\n",
        "        \"--threads\", str(threads),\n",
        "        \"--report\", str(report_path),\n",
        "        str(r1), str(r2),\n",
        "        str(out_prefix) + \".vdjca\",\n",
        "    ]\n",
        "    _run(align_cmd)\n",
        "    return str(out_prefix) + \".vdjca\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ9HH7ib0iXn"
      },
      "source": [
        "#MiXCR Core Steps (with caching)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "b8yY-6hl0ng2"
      },
      "outputs": [],
      "source": [
        "def mixcr_align(r1, r2, out_vdjca, report_path=None, threads=None, extra_args=None):\n",
        "    r1, r2, out_vdjca = map(str, (r1, r2, out_vdjca))\n",
        "    threads = threads or cpu_threads()\n",
        "    report = f\"--report {report_path}\" if report_path else \"\"\n",
        "    extra = \" \".join(extra_args) if extra_args else \"\"\n",
        "    if newer_than(out_vdjca, r1, r2):\n",
        "        print(f\"üîÅ [cache] align up-to-date: {out_vdjca}\")\n",
        "        return out_vdjca\n",
        "    sh(f\"mixcr align -t {threads} {report} {extra} {r1} {r2} {out_vdjca}\")\n",
        "    return out_vdjca\n",
        "\n",
        "def mixcr_assemble(in_vdjca, out_clns, report_path=None, threads=None, extra_args=None):\n",
        "    in_vdjca, out_clns = map(str, (in_vdjca, out_clns))\n",
        "    threads = threads or cpu_threads()\n",
        "    report = f\"--report {report_path}\" if report_path else \"\"\n",
        "    extra = \" \".join(extra_args) if extra_args else \"\"\n",
        "    if newer_than(out_clns, in_vdjca):\n",
        "        print(f\"üîÅ [cache] assemble up-to-date: {out_clns}\")\n",
        "        return out_clns\n",
        "    sh(f\"mixcr assemble -t {threads} {report} {extra} {in_vdjca} {out_clns}\")\n",
        "    return out_clns\n",
        "\n",
        "def mixcr_export_clones(in_clns, out_txt, preset=\"full\", extra_args=None):\n",
        "    in_clns, out_txt = map(str, (in_clns, out_txt))\n",
        "    extra = \" \".join(extra_args) if extra_args else \"\"\n",
        "    if newer_than(out_txt, in_clns):\n",
        "        print(f\"üîÅ [cache] export up-to-date: {out_txt}\")\n",
        "        return out_txt\n",
        "    sh(f\"mixcr exportClones --preset {preset} {extra} {in_clns} {out_txt}\")\n",
        "    return out_txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kumZchw04QP"
      },
      "source": [
        "#Chunking Utilities (SeqKit split2) ‚Äî for very large FASTQs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p1bIENWH05W2"
      },
      "outputs": [],
      "source": [
        "def split_fastq_gz(r1_gz, r2_gz, out_dir, chunk_reads=2_000_000, force=False, patient = \"\"):\n",
        "    out_dir = Path(out_dir)\n",
        "    r1_out = out_dir / f\"{patient}chunks_R1\"\n",
        "    r2_out = out_dir / f\"{patient}chunks_R2\"\n",
        "    r1_out.mkdir(parents=True, exist_ok=True)\n",
        "    r2_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # If chunks already exist and force==False, skip splitting\n",
        "    existing = list(r1_out.glob(\"*.fq.gz\")) or list(r1_out.glob(\"*.fastq.gz\"))\n",
        "    if existing and not force:\n",
        "        print(\"üîÅ [cache] chunks already exist ‚Äî skipping split\")\n",
        "        return r1_out, r2_out\n",
        "\n",
        "    sh(f\"seqkit split2 -s {chunk_reads} -O {r1_out} {r1_gz}\")\n",
        "    sh(f\"seqkit split2 -s {chunk_reads} -O {r2_out} {r2_gz}\")\n",
        "    return r1_out, r2_out\n",
        "\n",
        "def pair_chunk_files(r1_dir, r2_dir):\n",
        "    r1_dir, r2_dir = Path(r1_dir), Path(r2_dir)\n",
        "    r1_files = sorted([p for p in r1_dir.glob('*.fq.gz')] + [p for p in r1_dir.glob('*.fastq.gz')])\n",
        "    r2_files = sorted([p for p in r2_dir.glob('*.fq.gz')] + [p for p in r2_dir.glob('*.fastq.gz')])\n",
        "    # Pair by numeric suffix in filenames (seqkit uses part_001, part_002, ...)\n",
        "    def key(p):\n",
        "        s = p.stem  # remove .gz\n",
        "        s = s.replace(\".fastq\", \"\").replace(\".fq\", \"\")\n",
        "        # extract last number group\n",
        "        import re\n",
        "        m = re.findall(r\"(\\d+)$\", s)\n",
        "        return int(m[-1]) if m else -1\n",
        "    r1_files.sort(key=key)\n",
        "    r2_files.sort(key=key)\n",
        "    if len(r1_files) != len(r2_files):\n",
        "        raise ValueError(\"R1 and R2 chunk counts differ\")\n",
        "    return list(zip(r1_files, r2_files))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt-OETha1CKf"
      },
      "source": [
        "#Accelerated per-chunk alignment (thread budgeting + caching)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LTIWv0vF1A6X"
      },
      "outputs": [],
      "source": [
        "def align_chunks(r1_dir, r2_dir, out_dir, threads_total=None, per_job_min=2, extra_args=None):\n",
        "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    threads_total = threads_total or cpu_threads()\n",
        "    pairs = pair_chunk_files(r1_dir, r2_dir)\n",
        "    n_chunks = len(pairs)\n",
        "    if n_chunks == 0:\n",
        "        raise RuntimeError(\"No chunks found to align\")\n",
        "\n",
        "    # Determine jobs in parallel and threads per job\n",
        "    # Keep per-job threads >= per_job_min, and avoid oversubscription\n",
        "    max_jobs = max(1, threads_total // per_job_min)\n",
        "    jobs = min(max_jobs, n_chunks)\n",
        "    threads_per_job = max(per_job_min, threads_total // jobs)\n",
        "\n",
        "    print(f\"Threads total: {threads_total} | chunks: {n_chunks} | parallel jobs: {jobs} | threads/job: {threads_per_job}\")\n",
        "\n",
        "    futures = []\n",
        "    results = []\n",
        "\n",
        "    def do_align(i, r1, r2):\n",
        "        out_vdjca = out_dir / f\"chunk_{i:04d}.vdjca\"\n",
        "        rep = out_dir / f\"chunk_{i:04d}_align_report.txt\"\n",
        "        mixcr_align(r1, r2, out_vdjca, report_path=rep, threads=threads_per_job, extra_args=extra_args)\n",
        "        return str(out_vdjca)\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=jobs) as ex:\n",
        "        for i, (r1, r2) in enumerate(pairs, start=1):\n",
        "            futures.append(ex.submit(do_align, i, r1, r2))\n",
        "        for f in as_completed(futures):\n",
        "            results.append(f.result())\n",
        "\n",
        "    results = sorted(results)\n",
        "    print(f\"‚úÖ Completed {len(results)} chunk alignments\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpkfXEMy1FMX"
      },
      "source": [
        "#Merge chunked alignments, assemble, and export\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fV17SRv31JIe"
      },
      "outputs": [],
      "source": [
        "def merge_and_finalize(vdjca_list, merged_vdjca, clns_path, clones_txt, threads=None, export_preset=\"full\"):\n",
        "    merged_vdjca = str(merged_vdjca); clns_path = str(clns_path); clones_txt = str(clones_txt)\n",
        "    # Cache-aware: if merged_vdjca exists and newer than all parts, skip merge\n",
        "    def parts_newer_than(out, parts):\n",
        "        if not Path(out).exists():\n",
        "            return True\n",
        "        out_m = Path(out).stat().st_mtime\n",
        "        return any(Path(p).stat().st_mtime > out_m for p in parts)\n",
        "\n",
        "    if parts_newer_than(merged_vdjca, vdjca_list):\n",
        "        # mixcr mergeChunks requires vdjca args\n",
        "        args = \" \".join(map(str, vdjca_list))\n",
        "        sh(f\"mixcr mergeChunks {merged_vdjca} {args}\")\n",
        "    else:\n",
        "        print(f\"üîÅ [cache] merged VDJCA up-to-date: {merged_vdjca}\")\n",
        "\n",
        "    mixcr_assemble(merged_vdjca, clns_path, report_path=str(Path(clns_path).with_suffix('.assemble_report.txt')), threads=threads)\n",
        "    mixcr_export_clones(clns_path, clones_txt, preset=export_preset)\n",
        "    return merged_vdjca, clns_path, clones_txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJq2-O7l1PpG"
      },
      "source": [
        "#Detect read count, and choose chunk size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Xo-oAPVF1RM_"
      },
      "outputs": [],
      "source": [
        "def count_reads_fastq_gz(fastq_gz):\n",
        "    # Count lines / 4 = number of reads\n",
        "    cmd = f\"zcat {fastq_gz} | wc -l\"\n",
        "    lines = int(subprocess.check_output(cmd, shell=True).decode().strip())\n",
        "    return lines // 4\n",
        "\n",
        "def choose_chunk_size(total_reads, target_chunks=20, min_chunk=500_000, max_chunk=5_000_000):\n",
        "    chunk = max(min_chunk, min(max_chunk, total_reads // target_chunks))\n",
        "    return int(chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4i0sA1Y1Vc2"
      },
      "source": [
        "#High Level Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wYsAbkd11aaX"
      },
      "outputs": [],
      "source": [
        "def run_mixcr_pipeline(\n",
        "    fastq1, fastq2, work_dir, sample,\n",
        "    chunk_reads=None,                   # e.g., 2_000_000; if None => no chunking\n",
        "    mixcr_path=\"mixcr\",\n",
        "    preset=\"rna-seq\",\n",
        "    species=\"hsa\",\n",
        "    reads_layout=\"Collinear\",\n",
        "    total_threads=None,\n",
        "    force_split=False,\n",
        "    reuse_if_done=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Chunked MiXCR (faithful flags) ‚Üí assemble once across all chunks ‚Üí exportClones.\n",
        "    Produces: {work_dir}/{sample}_mixcr.clones.txt\n",
        "\n",
        "    Returns dict with output paths.\n",
        "    \"\"\"\n",
        "    work_dir = Path(work_dir)\n",
        "    work_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    final_clns   = work_dir / f\"{sample}_mixcr.clns\"\n",
        "    final_clones = work_dir / f\"{sample}_mixcr.clones.txt\"\n",
        "    assemble_report = work_dir / f\"{sample}_mixcr_assemble_report.txt\"\n",
        "\n",
        "    # Fast path: reuse final outputs\n",
        "    if reuse_if_done and final_clones.exists() and final_clns.exists():\n",
        "        print(f\"üîÅ [cache] Found final MiXCR outputs for {sample}, skipping.\")\n",
        "        return {\n",
        "            \"clns\": str(final_clns),\n",
        "            \"clones\": str(final_clones),\n",
        "            \"assemble_report\": str(assemble_report),\n",
        "        }\n",
        "\n",
        "    # --- Prepare chunks (or ‚Äúvirtual‚Äù single chunk) ---\n",
        "    if chunk_reads and int(chunk_reads) > 0:\n",
        "        # Safe split with seqkit (must be installed)\n",
        "        chunks_root = work_dir / \"chunks\"\n",
        "        r1_dir = chunks_root / f\"{sample}_chunks_R1\"\n",
        "        r2_dir = chunks_root / f\"{sample}_chunks_R2\"\n",
        "        r1_dir.mkdir(parents=True, exist_ok=True)\n",
        "        r2_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # If already split and not forced, reuse\n",
        "        existing = list(r1_dir.glob(\"*.fastq.gz\")) + list(r1_dir.glob(\"*.fq.gz\"))\n",
        "        if not existing or force_split:\n",
        "            # seqkit split2 -s <reads>\n",
        "            _run([\"seqkit\", \"split2\", \"-s\", str(int(chunk_reads)), \"-O\", str(r1_dir), str(fastq1)])\n",
        "            _run([\"seqkit\", \"split2\", \"-s\", str(int(chunk_reads)), \"-O\", str(r2_dir), str(fastq2)])\n",
        "        pairs = _pair_chunk_files(r1_dir, r2_dir)\n",
        "    else:\n",
        "        # No chunking: treat original pair as a single ‚Äúchunk‚Äù\n",
        "        pairs = [(Path(fastq1), Path(fastq2))]\n",
        "\n",
        "    n_chunks = len(pairs)\n",
        "    jobs, threads_per_job = _choose_parallelism(n_chunks, total_threads)\n",
        "    print(f\"[{sample}] Chunks: {n_chunks} | parallel jobs: {jobs} | threads/job: {threads_per_job}\")\n",
        "\n",
        "    aligned_dir = work_dir / \"aligned_chunks\"\n",
        "    aligned_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Align all chunks (parallel)\n",
        "    vdjca_paths = []\n",
        "    errors = []\n",
        "    if n_chunks == 1:\n",
        "        # single run, faithful command\n",
        "        out_prefix  = aligned_dir / f\"chunk_0001\"\n",
        "        report_file = aligned_dir / f\"chunk_0001_align_report.txt\"\n",
        "        try:\n",
        "            vdj = _align_one_chunk(mixcr_path, preset, species, reads_layout,\n",
        "                                   pairs[0][0], pairs[0][1], out_prefix, threads_per_job, report_file)\n",
        "            vdjca_paths.append(vdj)\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(e.stderr or e.output)\n",
        "            raise\n",
        "    else:\n",
        "        with ProcessPoolExecutor(max_workers=jobs) as ex:\n",
        "            futs = {}\n",
        "            for i, (r1, r2) in enumerate(pairs, start=1):\n",
        "                out_prefix  = aligned_dir / f\"chunk_{i:04d}\"\n",
        "                report_file = aligned_dir / f\"chunk_{i:04d}_align_report.txt\"\n",
        "                fut = ex.submit(\n",
        "                    _align_one_chunk,\n",
        "                    mixcr_path, preset, species, reads_layout,\n",
        "                    r1, r2, out_prefix, threads_per_job, report_file\n",
        "                )\n",
        "                futs[fut] = str(out_prefix) + \".vdjca\"\n",
        "\n",
        "            for fut in as_completed(futs):\n",
        "                try:\n",
        "                    vdj = fut.result()\n",
        "                    vdjca_paths.append(vdj)\n",
        "                except subprocess.CalledProcessError as e:\n",
        "                    errors.append(e)\n",
        "                    print(e.stderr or e.output)\n",
        "\n",
        "        if errors:\n",
        "            # Surface the first meaningful error\n",
        "            raise RuntimeError(f\"MiXCR align failed for {len(errors)}/{n_chunks} chunks. First error: {errors[0]}\")\n",
        "\n",
        "    # --- Assemble once across ALL chunked alignments ---\n",
        "    # MiXCR assemble accepts multiple .vdjca inputs; last positional is output .clns\n",
        "    assemble_cmd = [mixcr_path, \"assemble\", \"--threads\", str(max(1, int(total_threads or (os.cpu_count() or 1))))] \\\n",
        "                   + vdjca_paths + [str(final_clns)]\n",
        "    # optional report\n",
        "    assemble_cmd = assemble_cmd[:3] + [\"--report\", str(assemble_report)] + assemble_cmd[3:]\n",
        "    _run(assemble_cmd)\n",
        "\n",
        "    # --- Export clones (single output for whole sample) ---\n",
        "    export_cmd = [mixcr_path, \"exportClones\", str(final_clns), str(final_clones)]\n",
        "    _run(export_cmd)\n",
        "\n",
        "    print(f\"[{sample}] MiXCR complete ‚Üí {final_clones}\")\n",
        "    return {\n",
        "        \"clns\": str(final_clns),\n",
        "        \"clones\": str(final_clones),\n",
        "        \"assemble_report\": str(assemble_report),\n",
        "        \"vdjca_list\": vdjca_paths,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfRwN_9d8Fe3",
        "outputId": "e39798c3-577b-4004-a7a5-c0a4920a8d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying /content/drive/MyDrive/Bio_Informatics_RA_Assignment/Patient1/Patient1_merged_1.fastq.gz to /content/local_data/Patient1_merged_1.fastq.gz\n",
            "All FASTQ files copied to local disk.\n",
            "Locally stored paths are: {'Patient1': ('/content/local_data/Patient1_merged_1.fastq.gz', '/content/local_data/Patient1_merged_2.fastq.gz')}\n"
          ]
        }
      ],
      "source": [
        "# Stage data locally before starting parallel processes\n",
        "patient_files_dict = {patients[0]: patient_files}\n",
        "local_fastq_paths = stage_data_locally(patients, patient_files_dict, base_dir)\n",
        "print(f\"Locally stored paths are: {local_fastq_paths}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKAXeZOs4S9v",
        "outputId": "690762b9-8469-4ccc-bdad-055f6f8e467d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r1 Path: /content/local_data/Patient1_merged_1.fastq.gz\n",
            "r2 Path: /content/local_data/Patient1_merged_2.fastq.gz\n"
          ]
        }
      ],
      "source": [
        "r1 = local_fastq_paths[patients[0]][0]\n",
        "r2 = local_fastq_paths[patients[0]][1]\n",
        "print(f\"r1 Path: {r1}\")\n",
        "print(f\"r2 Path: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "Go868IeXvjvZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhDpswdN5O93",
        "outputId": "61bd6d13-a921-4bd1-b30a-14e87681beec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting reads this may take a while...\n",
            "Patient1 has 101745993 reads\n",
            "Choosing chunk size: 5000000\n",
            "Running MiXCR Test...\n",
            "$ seqkit split2 -s 5000000 -O /content/local_results/chunks/Patient1_chunks_R1 /content/local_data/Patient1_merged_1.fastq.gz\n",
            "$ seqkit split2 -s 5000000 -O /content/local_results/chunks/Patient1_chunks_R2 /content/local_data/Patient1_merged_2.fastq.gz\n",
            "[Patient1] Chunks: 21 | parallel jobs: 1 | threads/job: 2\n",
            "$ mixcr align --preset rna-seq --species hsa -OreadsLayout=Collinear --threads 2 --report /content/local_results/aligned_chunks/chunk_0001_align_report.txt /content/local_results/chunks/Patient1_chunks_R1/Patient1_merged_1.part_001.fastq.gz /content/local_results/chunks/Patient1_chunks_R2/Patient1_merged_2.part_001.fastq.gz /content/local_results/aligned_chunks/chunk_0001.vdjca\n",
            "$ mixcr align --preset rna-seq --species hsa -OreadsLayout=Collinear --threads 2 --report /content/local_results/aligned_chunks/chunk_0002_align_report.txt /content/local_results/chunks/Patient1_chunks_R1/Patient1_merged_1.part_002.fastq.gz /content/local_results/chunks/Patient1_chunks_R2/Patient1_merged_2.part_002.fastq.gz /content/local_results/aligned_chunks/chunk_0002.vdjca\n"
          ]
        }
      ],
      "source": [
        "print(\"Counting reads this may take a while...\")\n",
        "reads = count_reads_fastq_gz(r1)\n",
        "print(f\"Patient1 has {reads} reads\")\n",
        "chunk_size = choose_chunk_size(reads)\n",
        "print(f\"Choosing chunk size: {chunk_size}\")\n",
        "# MiXCR TEST\n",
        "try:\n",
        "  print(\"Running MiXCR Test...\")\n",
        "  run_mixcr_pipeline(r1, r2, local_results_dir, sample=\"Patient1\", chunk_reads=chunk_size)\n",
        "except Exception as e1:\n",
        "  print(f\"Error During MiXCR Test for Patient1: {e1}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}